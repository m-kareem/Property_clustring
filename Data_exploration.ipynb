{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "015fe828",
   "metadata": {},
   "source": [
    "# Property Clustring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ac150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4119cae8",
   "metadata": {},
   "source": [
    "## Structured Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58f0674",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1 — Load only what is needed\n",
    "use_cols = [\n",
    "    \"PropertyID\",\n",
    "    \"Currentavmvalue\",\n",
    "    \"equityValue\",\n",
    "    \"EquityPercent\",\n",
    "    \"LOO\",\n",
    "    \"Age\",\n",
    "    \"FinalOwnerType\",\n",
    "    \"Beds\",\n",
    "    \"FullBaths\",\n",
    "    \"HalfBaths\",\n",
    "    \"Sqft\",\n",
    "    \"building_condition\",\n",
    "    \"owneroccupied\",\n",
    "    \"multi_owner\",\n",
    "    \"Lien\"\n",
    "]\n",
    "\n",
    "df_combined = pd.read_csv(os.path.join(\"data\", \"combined_output.csv\"),\n",
    "    usecols=use_cols,\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "# print df shape\n",
    "print(\"df_combined shape: \", df_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95c67c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1610c5",
   "metadata": {},
   "source": [
    "### check/handle missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ec5722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values in percentage\n",
    "for col in df_combined.columns:\n",
    "    print(col, round(df_combined[col].isna().sum() / len(df_combined) * 100,2), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78be2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structurally reliable features (near-complete)\n",
    "tier1_col = [\n",
    "   'Currentavmvalue',\n",
    "   'equityValue',\n",
    "   'EquityPercent',\n",
    "   'FinalOwnerType',\n",
    "   'Age',\n",
    "   'LOO' \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8069d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2.1 — Encode informative missingness\n",
    "df_combined[\"LOO_missing\"] = df_combined[\"LOO\"].isna().astype(int)\n",
    "df_combined[\"Age_missing\"] = df_combined[\"Age\"].isna().astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127a22f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2.2 log transformation of LOO:\n",
    "# because Early tenure differences matter a lot, but Very long tenure differences matter less, so keeping LOO linear, means: “90 → 100 years is as important as 20 → 30 years.” \n",
    "# Which is almost certainly false behaviorally.\n",
    "\n",
    "df_combined[\"LOO_log\"] = np.log1p(df_combined[\"LOO\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1919ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2.3 - Encode Categorical features\n",
    "df_combined['is_AO'] = (df_combined['FinalOwnerType'] == 'AO').astype(int)\n",
    "#df_combined['is_OO'] = df_combined['FinalOwnerType'] == 'OO'  # redundant, as is_AO = 1 - is_OO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faec6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3.1 — AVM bins (binned current market valuation of the property) --> to be used at sampleing stage not clustering\n",
    "df_combined[\"AVM_bin\"] = pd.qcut(  # creates Equal-width bins\n",
    "    df_combined[\"Currentavmvalue\"],\n",
    "    q=10,\n",
    "    duplicates=\"drop\"\n",
    ")\n",
    "\n",
    "#step 3.2 - log transformation\n",
    "df_combined[\"Currentavmvalue_log\"] = np.log1p(df_combined[\"Currentavmvalue\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653387d2",
   "metadata": {},
   "source": [
    "#### # Age: Cap at 100 years\n",
    "##### “Age matters… until it doesn’t.”\n",
    "\n",
    "stop pretending we can distinguish degrees of ‘very old’ in a meaningful way”\n",
    "\n",
    "Without capping:\n",
    "- Age = 300 can dominate distance vs Age = 80\n",
    "- Even though both are “old” from an investor perspective\n",
    "- And even though other variables (equity, tenure) already encode the real signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8201b31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age: Cap at 100 years\n",
    "df_combined[\"is_very_old\"] = (df_combined[\"Age\"] > 100).astype(int)  # a secondary binary feature\n",
    "\n",
    "df_combined[\"Age_capped\"] = df_combined[\"Age\"].clip(upper=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec99c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined[\"Age_capped\"].plot.hist(bins=30, edgecolor=\"black\", rwidth=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8c9c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4 - Data cleaning\n",
    "# 1.drop rows with EquityPercent >100%\n",
    "df_combined = df_combined[df_combined[\"EquityPercent\"] <= 100]\n",
    "\n",
    "# EquityPercent == 100 must be treated as a state (is_fully_paid)\n",
    "df_combined[\"is_fully_paid\"] = (df_combined[\"EquityPercent\"] == 100).astype(int)\n",
    "\n",
    "# create continuous part of 'EquityPercent'\n",
    "df_combined[\"EquityPercent_cont\"] = df_combined[\"EquityPercent\"].where(\n",
    "    df_combined[\"EquityPercent\"] < 100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0739ef9",
   "metadata": {},
   "source": [
    "###  Stratified sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02007f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 — Stratified sampling\n",
    "target_size = 150_000\n",
    "sample_frac = target_size / len(df_combined)\n",
    "\n",
    "strata_cols = [\n",
    "    #\"FinalOwnerType\",\n",
    "    \"AVM_bin\",\n",
    "    \"LOO_missing\", # to get same fraction of missingness in the sample\n",
    "    \"Age_missing\"\n",
    "]\n",
    "\n",
    "\n",
    "#--\n",
    "#- Large strata contribute many rows\n",
    "#- Small but important strata are preserved\n",
    "#- Rare combinations don’t disappear\n",
    "#--\n",
    "sampled_df = (\n",
    "    df_combined\n",
    "    .groupby(strata_cols, group_keys=False, observed=False)\n",
    "    .apply(lambda x: x.sample(\n",
    "        frac=sample_frac,\n",
    "        random_state=42\n",
    "    ))\n",
    ")\n",
    "\n",
    "# step 5 — Save\n",
    "sampled_df.to_csv(os.path.join(\"data\",\n",
    "    \"combined_output_stratified_sample.csv\"),\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef897ed",
   "metadata": {},
   "source": [
    "NOTE: this sample is a faithful representation of the core investor-targetable population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205f6698",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0c51d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df[\"FinalOwnerType\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8868d32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined[\"FinalOwnerType\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da3fc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is Missingness preserved? (this is critical)\n",
    "sampled_df[[\"LOO_missing\", \"Age_missing\"]].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9945443",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined[[\"LOO_missing\", \"Age_missing\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62109f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVM distribution sanity\n",
    "sampled_df[\"Currentavmvalue\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87bec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['Currentavmvalue'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a50f344",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "the max in the sample vs original df shows discrapency.\n",
    "\n",
    "Are properties above $1.1M strategically meaningful for investor conversion?\n",
    "\n",
    "- If no → proceed as-is. The sample is fine. (Going with this option for now)\n",
    "\n",
    "- If yes → keep top 0.1% by AVM (sample separately) and sample the rest and then combine "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae01fc5",
   "metadata": {},
   "source": [
    "### Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3bedc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df['FinalOwnerType'].value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75f11b",
   "metadata": {},
   "source": [
    "==> 'FinalOwnerType' is dangerous and valuable. should not let FinalOwnerType directly drive distance in the first clustering pass. Should be excluded from distance metric to avoid trivial soltion:\n",
    "“Cluster 1 = AO, Cluster 2 = OO”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94afdd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df.groupby(\"FinalOwnerType\")[\n",
    "    [\"EquityPercent\", \"LOO_missing\"]\n",
    "].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc56df75",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "- Missing LOO is not explained by ownership type\n",
    "- AO tend to be further along the financial lifecycle/ But many OO are also high-equity/ And many AO are still leveraged\n",
    "\n",
    "so 'FinalOwnerType' should inform ranking, not geometry. It carries secondary interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b0ae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a 2 by 2 plot\n",
    "plt.figure(figsize=(30, 20))\n",
    "# tier1_col exclufing final owner type\n",
    "col = [c for c in tier1_col if c != \"FinalOwnerType\"]\n",
    "\n",
    "for i, col in enumerate(col):\n",
    "    ax = plt.subplot(3, 2, i + 1)\n",
    "    ax.set_title(col,fontsize=20)\n",
    "    sampled_df[col].plot.hist(bins=30, edgecolor=\"black\", rwidth=0.9)\n",
    "\n",
    "    missing_pct = sampled_df[col].isna().mean() * 100\n",
    "\n",
    "    ax.text(\n",
    "        0.98, 0.95,\n",
    "        f\"Missing: {missing_pct:.1f}%\",\n",
    "        transform=ax.transAxes,\n",
    "        ha=\"right\",\n",
    "        va=\"top\",\n",
    "        fontsize=14,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", alpha=0.3)\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bb12c9",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "\n",
    "### 1. EquityPercent = 100 is a proxy for ownership psychology, not just finance.\n",
    "\n",
    "From a behavioral standpoint, these owners are different:\n",
    "\n",
    "- Often long LOO\n",
    "- Often older properties\n",
    "- Frequently absentee owners\n",
    "- Emotionally detached from the property\n",
    "- Much easier investor conversations\n",
    "\n",
    "==> EquityPercent == 100, is_fully_paid? or EquityPercent_capped?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950cd825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many are fully paid?\n",
    "(sampled_df['is_fully_paid']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66e5acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship with LOO\n",
    "sampled_df.groupby(sampled_df['is_fully_paid'])[\"LOO\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac55f409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot LOO histogram for fully paid\n",
    "\n",
    "sampled_df[sampled_df['is_fully_paid']==1][\"LOO\"].plot.hist(bins=30, edgecolor=\"black\", rwidth=0.9)\n",
    "\n",
    "# set labels\n",
    "plt.xlabel(\"LOO (For fully paid properties)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "meanLoo = round(sampled_df[sampled_df['is_fully_paid']==1][\"LOO\"].mean(),1)\n",
    "# print the mean value\n",
    "#plt.text(100, 5000, f'mean LOO:{meanLoo}')\n",
    "plt.text(\n",
    "        0.3, 0.3,\n",
    "        f\"Mean: {meanLoo:.1f}\",\n",
    "        transform=ax.transAxes,\n",
    "        ha=\"right\",\n",
    "        va=\"top\",\n",
    "        fontsize=14,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", alpha=0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8813c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c7ad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot AO histograms for fully paid\n",
    "\n",
    "ownership_pct = sampled_df[sampled_df[\"is_fully_paid\"] == 1][\"is_AO\"].value_counts(normalize=True) * 100\n",
    "\n",
    "\n",
    "ax = ownership_pct.rename({1: \"Absentee owner\", 0: \"Owner Occupied\"}).plot.bar(\n",
    "    edgecolor=\"black\",\n",
    "    width=0.6\n",
    ")\n",
    "\n",
    "ax.set_ylabel(\"Percent of fully paid properties\")\n",
    "ax.set_xlabel(\"Owner type\")\n",
    "ax.set_title(\"Owner Type Distribution (Fully Paid Properties)\")\n",
    "\n",
    "# annotate bars\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.annotate(\n",
    "        f\"{height:.1f}%\",\n",
    "        (p.get_x() + p.get_width() / 2, height),\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\"\n",
    "    )\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64637e3d",
   "metadata": {},
   "source": [
    "==> Conclusion: \n",
    "- Fully paid ownership and absentee ownership are correlated, but not redundan\n",
    "- Baseline rate of AO is 52%\n",
    "- Being fully paid increases the likelihood of being absentee\n",
    "- is_AO is a good secondary explanatory variable\n",
    "    - If you had let is_AO into the distance metric --> Clusters would lean heavily toward AO/OO separation\n",
    "\n",
    "In investor terms, fully paid owners are:\n",
    "- More likely to be absentee (63.3%)\n",
    "- More likely to sell directly\n",
    "- Less constrained by lenders\n",
    "- But one in three fully paid owners still live in the home (36.7%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65233f44",
   "metadata": {},
   "source": [
    "### Missing LOO is not “unknown” — it’s a proxy state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0f66ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing_loo = sampled_df[sampled_df[\"LOO_missing\"]==1]\n",
    "df_non_missing_loo = sampled_df[sampled_df[\"LOO_missing\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2498278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_hist(ax, data, bins, xlabel, title):\n",
    "    weights = np.ones(len(data)) / len(data) * 100\n",
    "\n",
    "    ax.hist(\n",
    "        data,\n",
    "        bins=bins,\n",
    "        weights=weights,\n",
    "        edgecolor=\"black\",\n",
    "        rwidth=0.9\n",
    "    )\n",
    "\n",
    "    #ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(\"Percent of observations\")\n",
    "    ax.set_title(title)\n",
    "    ax.yaxis.set_major_formatter(lambda y, _: f\"{y:.0f}%\")\n",
    "\n",
    "    # annotate bars\n",
    "    for patch in ax.patches:\n",
    "        height = patch.get_height()\n",
    "        if height > 0:\n",
    "            ax.annotate(\n",
    "                f\"{height:.1f}%\",\n",
    "                (patch.get_x() + patch.get_width() / 2, height),\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "                fontsize=8\n",
    "            )\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# --- Row 1: EquityPercent ---\n",
    "percent_hist(\n",
    "    ax=axes[0, 0],\n",
    "    data=df_missing_loo[\"EquityPercent\"],\n",
    "    bins=20,\n",
    "    xlabel=\"EquityPercent\",\n",
    "    title=\"EquityPercent (LOO missing)\"\n",
    ")\n",
    "\n",
    "percent_hist(\n",
    "    ax=axes[0, 1],\n",
    "    data=sampled_df[\"EquityPercent\"],\n",
    "    bins=20,\n",
    "    xlabel=\"EquityPercent\",\n",
    "    title=\"EquityPercent (All properties)\"\n",
    ")\n",
    "\n",
    "# --- Row 2: Age ---\n",
    "percent_hist(\n",
    "    ax=axes[1, 0],\n",
    "    data=sampled_df[\"Age\"].dropna(),\n",
    "    bins=20,\n",
    "    xlabel=\"Age\",\n",
    "    title=\"Age (All properties)\"\n",
    ")\n",
    "\n",
    "percent_hist(\n",
    "    ax=axes[1, 1],\n",
    "    data=df_missing_loo[\"Age\"].dropna(),\n",
    "    bins=20,\n",
    "    xlabel=\"Age\",\n",
    "    title=\"Age (LOO missing)\"\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a12a75c",
   "metadata": {},
   "source": [
    "==> conclusion:\n",
    "- LOO has two meanings depending on whether it exists.\n",
    "    - Majority of missing LOO are fully paied properties ~ 71%\n",
    "- Age distribution does not matter in LOO (Missing LOO is not about the house being older)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14227bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df[sampled_df['LOO'].notna()]['LOO'].plot.hist(bins=30, edgecolor=\"black\", rwidth=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f03487",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df['Currentavmvalue'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e34934",
   "metadata": {},
   "source": [
    "## Assembling a model of ownership behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c27024",
   "metadata": {},
   "source": [
    "#### Step 1 — Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97abcfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_features = [\n",
    "    \"Currentavmvalue_log\",\n",
    "    \"is_fully_paid\",\n",
    "    \"EquityPercent_cont\",\n",
    "    \"LOO_log\",\n",
    "    \"LOO_missing\",\n",
    "    \"Age_capped\"\n",
    "]\n",
    "\n",
    "X = sampled_df[cluster_features]\n",
    "\n",
    "X.info()\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbe8d12",
   "metadata": {},
   "source": [
    "#### Step 2 — Handle intentional NaNs\n",
    "\n",
    "For distance-based clustering, the cleanest option is:\n",
    "\n",
    "- Replace intentional NaNs with 0\n",
    "- Rely on the corresponding binary flag to explain why it’s zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167efa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filled = X.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0bc76d",
   "metadata": {},
   "source": [
    "#### Step 3 — Scaling\n",
    "we have\n",
    "- Continuous variables (log AVM, LOO_log, Age_capped) ==> comparable in scale\n",
    "- Binary variables (is_fully_paid, LOO_missing) ==> retain meaning (0 vs 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86fa88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26510bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_scaled is a numpy array\n",
    "X_scaled_df = pd.DataFrame(\n",
    "    X_scaled,\n",
    "    columns=cluster_features,\n",
    "    index=sampled_df.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0d0b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f7a6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "for i, col in enumerate(cluster_features):\n",
    "    ax = plt.subplot(3, 2, i + 1)\n",
    "    X_scaled_df[col].plot.hist(\n",
    "        bins=30,\n",
    "        edgecolor=\"black\",\n",
    "        rwidth=0.9,\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_title(col)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d87ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    X_scaled_df.corr(),\n",
    "    annot=True,\n",
    "    cmap=\"coolwarm\",\n",
    "    center=0\n",
    ")\n",
    "plt.title(\"Correlation Between Scaled Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef910374",
   "metadata": {},
   "source": [
    "==> Conclusion: the high correlation is by design, not a problem. e.g.:\n",
    "- is_fully_paid: Binary state\n",
    "- EquityPercent_cont: Continuous degree\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed980b6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Algorithm 1: KMeans (first try)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d377e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(\n",
    "    n_clusters=6,\n",
    "    random_state=42,\n",
    "    n_init=20\n",
    ")\n",
    "\n",
    "labels = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "sampled_df[\"cluster\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9844b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df.groupby(\"cluster\")[cluster_features].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f352ed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df.groupby(\"cluster\")[\"is_AO\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0a30cf",
   "metadata": {},
   "source": [
    "==> conclusion: Clusters are not trivially “AO vs OO”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e59b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df.groupby(\"cluster\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd4d781",
   "metadata": {},
   "source": [
    "### ==> Result interpretation of Algo 1: KMeans (first try)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff52843c",
   "metadata": {},
   "source": [
    "#### 1. First sanity verdict\n",
    "\n",
    "Before details:\n",
    "\n",
    "* ✅ No single cluster dominates (sizes are reasonable)\n",
    "* ✅ No cluster is tiny/noise\n",
    "* ✅ Clusters are not trivially “AO vs OO”\n",
    "* ✅ Equity regime, tenure regime, and AVM are all participating\n",
    "\n",
    "This means:\n",
    "\n",
    "> **The geometry is healthy.**\n",
    "\n",
    "Now we can reason.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Read the clusters as *ownership personas*\n",
    "\n",
    "I’ll label them behaviorally (not numerically). These are *working labels*, not final names.\n",
    "\n",
    "---\n",
    "\n",
    "##### Cluster 0 — *Legacy Fully Paid, Data-Poor*\n",
    "\n",
    "* `is_fully_paid = 1`\n",
    "* `LOO_missing = 1`\n",
    "* `Age_capped ≈ 66`\n",
    "* AO ≈ **55%**\n",
    "* Mid AVM\n",
    "\n",
    "**Interpretation**\n",
    "Old ownership, fully paid, missing tenure records. Likely inherited or very long-held properties.\n",
    "\n",
    "**Investor signal**\n",
    "Strong. Classic “legacy owner” profile.\n",
    "\n",
    "---\n",
    "\n",
    "##### Cluster 2 — *Very Old, Fully Paid, Recorded Tenure*\n",
    "\n",
    "* `is_fully_paid = 1`\n",
    "* `LOO_log ≈ 3.01` (very long)\n",
    "* `Age_capped ≈ 82`\n",
    "* AO ≈ **58%**\n",
    "* Lower AVM\n",
    "\n",
    "**Interpretation**\n",
    "Physically old homes, very long tenure, fully paid.\n",
    "\n",
    "**Investor signal**\n",
    "High motivation potential, but watch condition / rehab risk.\n",
    "\n",
    "---\n",
    "\n",
    "##### Cluster 5 — *Fully Paid, High-Value, AO-Dominant*\n",
    "\n",
    "* `is_fully_paid = 1`\n",
    "* `LOO_log ≈ 3.00`\n",
    "* `Age_capped ≈ 43`\n",
    "* AO ≈ **75%** (highest)\n",
    "* Highest AVM among fully paid\n",
    "\n",
    "**Interpretation**\n",
    "Absentee, fully paid, relatively newer homes, higher value.\n",
    "\n",
    "**Investor signal**\n",
    "**Top-tier target cluster**. This is exactly what the business wants.\n",
    "\n",
    "---\n",
    "\n",
    "##### Cluster 1 — *Leveraged, Younger, Shorter Tenure*\n",
    "\n",
    "* `is_fully_paid = 0`\n",
    "* `EquityPercent ≈ 60`\n",
    "* `LOO_log ≈ 2.73`\n",
    "* `Age_capped ≈ 38`\n",
    "* AO ≈ **45%**\n",
    "* Highest AVM overall\n",
    "\n",
    "**Interpretation**\n",
    "Active ownership, still leveraged, likely listing-oriented.\n",
    "\n",
    "**Investor signal**\n",
    "Lower. Probably not your best mailing spend.\n",
    "\n",
    "---\n",
    "\n",
    "##### Cluster 3 — *Leveraged, Old Property, Long Tenure*\n",
    "\n",
    "* `is_fully_paid = 0`\n",
    "* `EquityPercent ≈ 60`\n",
    "* `LOO_log ≈ 2.76`\n",
    "* `Age_capped ≈ 80`\n",
    "* AO ≈ **38%**\n",
    "\n",
    "**Interpretation**\n",
    "Old homes, long tenure, but still leveraged.\n",
    "\n",
    "**Investor signal**\n",
    "Mixed. Equity exists, but mortgage friction remains.\n",
    "\n",
    "---\n",
    "\n",
    "##### Cluster 4 — *Leveraged, Missing LOO, Mid-Age*\n",
    "\n",
    "* `is_fully_paid = 0`\n",
    "* `LOO_missing = 1`\n",
    "* `EquityPercent ≈ 70`\n",
    "* `Age_capped ≈ 58`\n",
    "* AO ≈ **39%**\n",
    "\n",
    "**Interpretation**\n",
    "Odd hybrid: higher equity but missing tenure records.\n",
    "\n",
    "**Investor signal**\n",
    "Worth investigating. Possibly legacy data + partial refi history.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. What this tells us about the model\n",
    "\n",
    "### ✅ Equity did NOT hijack everything\n",
    "\n",
    "Fully paid clusters split into **three distinct personas** (0, 2, 5).\n",
    "\n",
    "That’s exactly what we wanted.\n",
    "\n",
    "### ✅ LOO_missing is doing real work\n",
    "\n",
    "Clusters 0 and 4 exist *because* of it.\n",
    "\n",
    "### ✅ Age is stabilizing, not dominating\n",
    "\n",
    "Age separates clusters *within* regimes, but doesn’t define them.\n",
    "\n",
    "### ✅ AO is emergent, not forced\n",
    "\n",
    "Cluster 5 surfaced as AO-heavy *without* AO in the feature space.\n",
    "\n",
    "That’s a huge validation.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. The most important insight so far\n",
    "\n",
    "> **Cluster 5 is our gold cluster.**\n",
    "\n",
    "High AO, fully paid, higher AVM, decent property age.\n",
    "\n",
    "That is exactly the profile:\n",
    "\n",
    "* Investors love\n",
    "* Mail converts\n",
    "* Margins tend to be higher\n",
    "\n",
    "Everything we do next should be judged by:\n",
    "\n",
    "> “Does this sharpen our understanding of Cluster 5 and its neighbors?”\n",
    "\n",
    "---\n",
    "\n",
    "## 5. NEXT\n",
    "\n",
    "### **Step 1 — Stability check **\n",
    "\n",
    "Run KMeans with different `k` values:\n",
    "\n",
    "* `k = 5, 6, 7, 8`\n",
    "\n",
    "Then check:\n",
    "\n",
    "* Does Cluster 5 persist?\n",
    "* Does it split meaningfully or dissolve?\n",
    "* Do legacy clusters remain stable?\n",
    "\n",
    "If your best cluster vanishes at `k=7`, that’s a warning.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 2 — Translate centroids back to real units**\n",
    "\n",
    "Right now you’re reading *means*, which is good—but next you should inspect **medians** and **percentiles**, especially for:\n",
    "\n",
    "* AVM\n",
    "* EquityPercent\n",
    "* LOO\n",
    "\n",
    "Means lie in skewed distributions.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 3 — Attach outcomes (this is where money enters)**\n",
    "\n",
    "Now we bring in:\n",
    "`StuckAcqs_4thDecember2025_analysis`\n",
    "\n",
    "Join on PropertyID (or equivalent), and compute per cluster:\n",
    "\n",
    "* Conversion rate\n",
    "* Avg gross margin\n",
    "* Margin per mailed property\n",
    "\n",
    "This will answer:\n",
    "\n",
    "> “Does Cluster 5 actually pay?”\n",
    "\n",
    "If yes → it becomes your anchor segment.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 4 — Decide if KMeans is “good enough”**\n",
    "\n",
    "After outcome analysis:\n",
    "\n",
    "* If clusters are stable and profitable → keep KMeans\n",
    "* If clusters bleed together → consider:\n",
    "\n",
    "  * Gaussian Mixture Models (soft membership)\n",
    "  * Hierarchical clustering (for sub-segmentation)\n",
    "\n",
    "But **do not jump algorithms yet**.\n",
    "KMeans has earned its seat so far.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. What NOT to do yet\n",
    "\n",
    "* ❌ Do not optimize silhouette score\n",
    "* ❌ Do not add AO into features\n",
    "* ❌ Do not add Sqft/Beds yet\n",
    "* ❌ Do not over-tune k\n",
    "\n",
    "We are still in **structure validation**, not optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04835fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Stability check\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "k_values = [5, 6, 7, 8]\n",
    "cluster_results = {}\n",
    "\n",
    "for k in k_values:\n",
    "    km = KMeans(\n",
    "        n_clusters=k,\n",
    "        random_state=42,\n",
    "        n_init=20\n",
    "    )\n",
    "    labels = km.fit_predict(X_scaled)\n",
    "    cluster_results[k] = labels\n",
    "\n",
    "# remove previous clustring column\n",
    "sampled_df.drop(\"cluster\", axis=1, inplace=True)\n",
    "\n",
    "for k, labels in cluster_results.items():\n",
    "    sampled_df[f\"cluster_k{k}\"] = labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d50f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare cluster profiles\n",
    "for k in k_values:\n",
    "    print(f\"\\n=== k = {k} ===\")\n",
    "    display(\n",
    "        sampled_df\n",
    "        .groupby(f\"cluster_k{k}\")[cluster_features + [\"is_AO\"]]\n",
    "        .mean()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e94c47c",
   "metadata": {},
   "source": [
    "==> Conclusion:\n",
    "- k = 5 → too coarse\n",
    "- k = 6 → minimum viable resolution\n",
    "- k = 7, 8 → refinement, not distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e17aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Compute their membership overlap\n",
    "\n",
    "gold_k6 = sampled_df.loc[\n",
    "    (sampled_df[\"cluster_k6\"] == 5)  # 5 is the gold cluster id in k=6\n",
    "].index\n",
    "\n",
    "gold_k7 = sampled_df.loc[\n",
    "    (sampled_df[\"cluster_k7\"] == 0)  # 0 is the gold cluster id in k=7\n",
    "].index\n",
    "\n",
    "overlap = len(gold_k6.intersection(gold_k7)) / len(gold_k6)\n",
    "overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128fa717",
   "metadata": {},
   "source": [
    "==> Conclusion:\n",
    "\n",
    "- high overlap means: The same properties are being grouped together\n",
    "- Increasing k is not changing membership\n",
    "- The model is just refining the rest of the space by increasing k\n",
    "\n",
    "So, This cluster is not an artifact of k. It is a true basin in the data geometry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7c1dfa",
   "metadata": {},
   "source": [
    "### Profit Validation: Does this gold cluster actually make more money?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd594a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv file\n",
    "df_stuckAcqs = pd.read_csv(os.path.join(\"data\", \"StuckAcqs_4thDecember2025_analysis.csv\"))\n",
    "\n",
    "# print df length\n",
    "print(\"df_stuckAcqs shape: \", df_stuckAcqs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbf7291",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stuckAcqs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3123b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stuckAcqs[\"PropertyID_join\"] = (\n",
    "    df_stuckAcqs[\"FA Prop Id\"]\n",
    "    .dropna()\n",
    "    .astype(\"int64\")\n",
    "    .astype(str)\n",
    ")\n",
    "\n",
    "df_combined[\"PropertyID_join\"] = df_combined[\"PropertyID\"].astype(str)\n",
    "sampled_df[\"PropertyID_join\"] = sampled_df[\"PropertyID\"].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7ee76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify overlap\n",
    "overlap_rate = df_stuckAcqs[\"PropertyID_join\"].isin(\n",
    "    sampled_df[\"PropertyID_join\"]\n",
    ").mean()\n",
    "\n",
    "overlap_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f068ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_joined = sampled_df.merge(\n",
    "    df_stuckAcqs[[\"PropertyID_join\", \"Gross Margin\"]],\n",
    "    on=\"PropertyID_join\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2897b2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_joined[\"Gross Margin\"].notna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d4ffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename cluster_k6 to cluster\n",
    "sampled_joined.rename(columns={\"cluster_k6\": \"cluster\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d90d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4523e9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_joined.groupby(\"cluster\")[\"Gross Margin\"].apply(\n",
    "    lambda x: x.notna().mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383b1b9a",
   "metadata": {},
   "source": [
    "==> conclusion: the “gold cluster” is not just interpretable — it actually converts more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f020693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion counts by cluster & toral / average margin\n",
    "\n",
    "sampled_joined.groupby(\"cluster\").agg(\n",
    "    total_props=(\"PropertyID_join\", \"size\"),\n",
    "    converted=(\"Gross Margin\", lambda x: x.notna().sum()),\n",
    "    avg_margin=(\"Gross Margin\", \"mean\"),\n",
    "    total_margin=(\"Gross Margin\", \"sum\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9b2ccd",
   "metadata": {},
   "source": [
    "==> Conclusion:\n",
    "\n",
    "- Cluster 5\n",
    "    - $113,582 / 26,935 ≈ $4.22 per property\n",
    "\n",
    "- Cluster 1\n",
    "    - $72,390 / 41,735 ≈ $1.73 per property\n",
    "\n",
    "- Cluster 3\n",
    "    - $42,178 / 25,647 ≈ $1.64 per property"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836c9c22",
   "metadata": {},
   "source": [
    "#### Profile Cluster 5 deeper\n",
    "\n",
    "- should check the location of the converted properties in this cluster (in the center or at the extreams, ...)\n",
    "- is the cluster tight enough or should we look at sub-clusters inside it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c995810",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_cluster_5 = sampled_joined[sampled_joined['cluster']==5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8ea1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sampled_cluster_5), sampled_cluster_5[\"Gross Margin\"].notna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b7c68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_check = [\n",
    "    \"Currentavmvalue_log\",\n",
    "    \"Age_capped\",\n",
    "    \"LOO_log\",\n",
    "    \"is_AO\"\n",
    "]\n",
    "\n",
    "sampled_cluster_5.groupby(sampled_cluster_5[\"Gross Margin\"].notna())[cols_to_check].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc70a432",
   "metadata": {},
   "source": [
    "==> conclusion:\n",
    "- Conversions are not edge cases of Cluster 5.\n",
    "- They sit near the center, with mild enrichment on AVM and Age, and a strong AO signal.\n",
    "- No need to sub-cluster Cluster 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3750d59",
   "metadata": {},
   "source": [
    "### Scale this model to the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c538cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = df_combined[cluster_features].copy()\n",
    "X_full_filled = X_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1601ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full_scaled = scaler.transform(X_full_filled)\n",
    "X_full_scaled.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce543de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined[\"cluster\"] = kmeans.predict(X_full_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a5da7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined[\"cluster\"].value_counts(normalize=True).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7723ed",
   "metadata": {},
   "source": [
    "==> Conclusion:\n",
    "- Full universe ≈ 5.3M\n",
    "- Cluster 5 ≈ 17.8%  --> almost exactly macthes the sampled dataset fraction\n",
    "\n",
    "That’s on the order of ~940k properties, We’re not mailing all of them --> Need to be selective inside Cluster 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958abb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df[\"cluster_k6\"].value_counts(normalize=True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4305e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined[df_combined[\"cluster\"] == 5][cluster_features].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3075f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_joined = df_combined.merge(\n",
    "    df_stuckAcqs[[\"PropertyID_join\", \"Gross Margin\"]],\n",
    "    on=\"PropertyID_join\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "df_combined_joined[\"Gross Margin\"].notna().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e9ca54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_joined.groupby(\"cluster\").agg(\n",
    "    total_props=(\"PropertyID_join\", \"size\"),\n",
    "    converted=(\"Gross Margin\", lambda x: x.notna().sum()),\n",
    "    avg_margin=(\"Gross Margin\", \"mean\"),\n",
    "    total_margin=(\"Gross Margin\", \"sum\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a06c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_joined.groupby(\"cluster\").apply(\n",
    "    lambda x: x[\"Gross Margin\"].sum() / len(x)\n",
    ").rename(\"margin_per_property\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ad28e0",
   "metadata": {},
   "source": [
    "---\n",
    "### Apply the existing model to df_stuckAcqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21f2703",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stuckAcqs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e5d6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stuckAcqs['Equity'] = df_stuckAcqs['Equity'].str.replace('%', '')\n",
    "df_stuckAcqs[\"Equity_pct\"] = pd.to_numeric(\n",
    "    df_stuckAcqs[\"Equity\"],\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "df_stuckAcqs['Equity_pct'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89365679",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stuckAcqs[\"Equity_pct\"].isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf235af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstructing the cluster features in the stuckAcqs dataset\n",
    "cluster_features = [\n",
    "    \"Currentavmvalue_log\",\n",
    "    \"is_fully_paid\",\n",
    "    \"EquityPercent_cont\",\n",
    "    \"LOO_log\",\n",
    "    \"LOO_missing\",\n",
    "    \"Age_capped\"\n",
    "]\n",
    "\n",
    "cluster_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509666f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1) AVM (log)\n",
    "df_stuckAcqs[\"Currentavmvalue_log\"] = np.log1p(df_stuckAcqs[\"AVM\"])\n",
    "\n",
    "# 2) is_fully_paid (strict, conservative definition)\n",
    "df_stuckAcqs[\"is_fully_paid\"] = (\n",
    "    (df_stuckAcqs[\"Equity_pct\"] == 100) &\n",
    "    (df_stuckAcqs[\"Total Mortgage\"].fillna(0) <= 1)\n",
    ").astype(int)\n",
    "\n",
    "# 3) EquityPercent_cont (only when not fully paid)\n",
    "df_stuckAcqs[\"EquityPercent_cont\"] = df_stuckAcqs[\"Equity_pct\"].where(\n",
    "    df_stuckAcqs[\"Equity_pct\"] < 100\n",
    ")\n",
    "\n",
    "# 4) LOO_log\n",
    "df_stuckAcqs[\"LOO_log\"] = np.log1p(df_stuckAcqs[\"LOO\"])\n",
    "\n",
    "# 5) LOO_missing\n",
    "df_stuckAcqs[\"LOO_missing\"] = df_stuckAcqs[\"LOO\"].isna().astype(int)\n",
    "\n",
    "# 6) Age_capped\n",
    "df_stuckAcqs[\"Age_capped\"] = df_stuckAcqs[\"Age\"].clip(upper=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1961200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missingness check\n",
    "df_stuckAcqs[\n",
    "    [\n",
    "        \"Currentavmvalue_log\",\n",
    "        \"is_fully_paid\",\n",
    "        \"EquityPercent_cont\",\n",
    "        \"LOO_log\",\n",
    "        \"LOO_missing\",\n",
    "        \"Age_capped\"\n",
    "    ]\n",
    "].isna().mean()\n",
    "\n",
    "# Sanity distributions\n",
    "#df_stuckAcqs[\"is_fully_paid\"].value_counts(dropna=False)\n",
    "#df_stuckAcqs[\"EquityPercent_cont\"].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde6dd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missingness check\n",
    "sampled_df[\n",
    "    [\n",
    "        \"Currentavmvalue_log\",\n",
    "        \"is_fully_paid\",\n",
    "        \"EquityPercent_cont\",\n",
    "        \"LOO_log\",\n",
    "        \"LOO_missing\",\n",
    "        \"Age_capped\"\n",
    "    ]\n",
    "].isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a160e271",
   "metadata": {},
   "source": [
    "### ==> Why we cannot apply the model directly on the df_stuckAcqs:\n",
    "\n",
    "- `df_stuckAcqs` is an outcome / acquisition table, not a feature-complete representation of the mailing universe the clustering model was trained on.\n",
    "- Several core clustering features are missing at high rates in df_stuckAcqs:\n",
    "    - ~22% missing AVM\n",
    "    - ~76% missing equity depth\n",
    "    - ~53% missing length of ownership (LOO)\n",
    "- Applying the model directly would break the feature geometry and cause cluster assignments to be driven by missingness and imputed values rather than real property behavior.\n",
    "- Filtering to “compatible” rows would introduce selection bias, because it conditions on data availability rather than underlying economics or owner behavior.\n",
    "- Any clusters produced directly on df_stuckAcqs would therefore be methodologically invalid and misleading.\n",
    "- The correct way to evaluate cluster performance is to join acquisitions onto the full mailing universe and measure expected value per property, which is the approach we used to identify Cluster 5 as the gold segment.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1a526d",
   "metadata": {},
   "source": [
    "---\n",
    "### Designing a scoring/ ranking model\n",
    "Who is most likely to convert?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26367a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df_combined_joined[df_combined_joined[\"cluster\"] == 5]\n",
    "\n",
    "df5.groupby(df5[\"Gross Margin\"].notna()).agg(\n",
    "    count=(\"PropertyID_join\", \"size\"),\n",
    "    ao_rate=(\"is_AO\", \"mean\"),\n",
    "    avg_avm=(\"Currentavmvalue_log\", \"mean\"),\n",
    "    avg_age=(\"Age_capped\", \"mean\"),\n",
    "    avg_LOO=(\"LOO_log\", \"mean\"),\n",
    "    loo_missing_rate=(\"LOO_missing\", \"mean\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457feff6",
   "metadata": {},
   "source": [
    "==> Conclusions:\n",
    "\n",
    "1️. Cluster membership is the base score\n",
    "\n",
    "- Dominant effect\n",
    "- Largest lift\n",
    "- Stable and interpretable\n",
    "\n",
    "2. Within Cluster 5, refinements are:\n",
    "\n",
    "- AO → strong positive\n",
    "- AVM → moderate positive\n",
    "- Age → optional / very weak (can be ignored initially)\n",
    "\n",
    "3. LOO does not matter inside Cluster 5\n",
    "\n",
    "- Consistent with sample\n",
    "- We explicitly exclude it from the score refinement"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
